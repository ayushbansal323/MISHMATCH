# -*- coding: utf-8 -*-
"""MISHMASTCH 2nd hurdle baysian forcasting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pNtjMpkSgbYAvBPmakzaUOG4IrBPGQTn
"""

!pip install pymc3
!pip install arviz

"""# Bayesian Linear Regression

## Exploratory Data Analysis

Kindly note that **Print_Impressions.Ads40** column is changed to **Print_Impressions_Ads40** and **Print_Working_Cost.Ads50** to **Print_Working_Cost_Ads50**
"""

import pymc3 as pm
import pandas as pd
df = pd.read_csv('TrainingData.csv')
df = df.drop(columns=['Period'])

#filling the missing values with the mean
for col in df.columns:
  if col != 'Period':
    df[col] = df[col].fillna((df[col].mean()))
df.head()

import matplotlib.pyplot as plt
import numpy as np

for i in df:
    df[i] = np.log(df[i]) 
for i in df:
  plt.hist(df[i], bins = 14)
  plt.xlabel(i)
  plt.ylabel('Time')
  plt.title('Distribution of '+i)
  plt.show()

"""## Corelation

Finding the correlation between every feature with respect to EQ
"""

df.corr()['EQ'].sort_values()

# Drop the features which have low correlation and are not distributed properly
df = df.drop(columns=['Competitor1_RPI',
                      'Competitor2_RPI',
                      'Competitor3_RPI',
                      'Competitor4_RPI',
                      ])

from sklearn.model_selection import train_test_split
labels = df['EQ']
# df is features and labels are the targets 
# Split by putting 0.5% in the testing set
X_train, X_test, y_train, y_test = train_test_split(df, labels, 
                                                   test_size = 0.005,
                                                    random_state=42)

# Formula for Bayesian Linear Regression (follows R formula syntax
formula = 'EQ ~ ' + ' + '.join(['%s' % variable for variable in X_train.columns[1:]])
formula

import pymc3 as pm

# Context for the model
with pm.Model() as normal_model:
    
    # The prior for the data likelihood is a Normal Distribution
    family = pm.glm.families.Normal()
    
    # Creating the model requires a formula and data (and optionally a family)
    pm.GLM.from_formula( formula,data = X_train, family = family)
    
    # Draw the specified number of samples
    normal_trace = pm.sample(draws=150, chains = 1, tune = 50, cores=-1)

import pickle
# save the model to disk
filename = 'finalized_model.sav'
pickle.dump(normal_model, open(filename, 'wb'))

pm.summary(normal_trace)



# Calculate mae and rmse
def evaluate_predictions(predictions, true):
    mae = np.mean(abs(predictions - true))
    rmse = np.sqrt(np.mean((predictions - true) ** 2))
    
    return mae, rmse

model_formula = 'EQ = '
for variable in normal_trace.varnames:
    model_formula += ' %0.2f * %s +' % (np.mean(normal_trace[variable]), variable)

' '.join(model_formula.split(' ')[:-1])

# Evalute the MCMC trace and compare to ml models
import matplotlib.pyplot as plt
def evaluate_trace(trace, Xtest, ytest):
    print('Hello')
    # Dictionary of all sampled values for each parameter
    var_dict = {}
    for variable in trace.varnames:
        var_dict[variable] = trace[variable]
        
    # Results into a dataframe
    var_weights = pd.DataFrame(var_dict)
    
    # Means for all the weights
    var_means = var_weights.mean(axis=0)
    
    # Create an intercept column
    Xtest['Intercept'] = 1
    
    # Align names of the test observations and means
    names = Xtest.columns[1:]
    Xtest = Xtest.loc[:, names]
    
    var_means = var_means[names]
    
    # Calculate estimate for each test observation using the average weights
    results = pd.DataFrame(index = Xtest.index, columns = ['EQ'],dtype=np.float32)
    
    for row in Xtest.iterrows():
        results.loc[row[0], 'EQ'] = np.dot(np.array(var_means), np.array(row[1]))

    
    # Metrics 
    actual = np.array(ytest)
    errors = np.exp(results['EQ']) - np.exp(actual)
    mae = np.mean(abs(errors))
    rmse = np.sqrt(np.mean(errors ** 2))
    mape = np.mean(np.abs((np.exp(results['EQ']) - np.exp(actual)) /np.exp(actual))) * 100 
    print('Model  MAE: {:.4f}\nModel RMSE: {:.4f} \nModel MAPE: {:.4f}'.format(mae, rmse, mape))
    print()
    
    lst = [i for i in range(len(actual))]
    plt.plot(lst,np.exp(results['EQ']), label = "predict")
    plt.plot(lst,np.exp(actual), label = "actual")
    plt.legend()
    plt.show()
    return results

all_model_results = evaluate_trace(normal_trace, X_test, y_test)

# Naive baseline is the median
median_pred = X_train['EQ'].median()
median_preds = [median_pred for _ in range(len(X_test))]
true = X_test['EQ']
# Display the naive baseline metrics
mb_mae, mb_rmse = evaluate_predictions(np.exp(median_preds), np.exp(true))
print('Median Baseline  MAE: {:.4f}'.format(mb_mae))
print('Median Baseline RMSE: {:.4f}'.format(mb_rmse))

import pymc3 as pm
import pandas as pd
test = pd.read_csv('TestData.csv')
test = test.drop(columns=['Period'])
for col in test.columns:
  if col != 'Period':
    test[col] = test[col].fillna((test[col].mean()))
test.head()

# Drop the features which have low correlation and are not distributed properly
test = test.drop(columns=['Competitor1_RPI',
                      'Competitor2_RPI',
                      'Competitor3_RPI',
                      'Competitor4_RPI',])

import matplotlib.pyplot as plt
import numpy as np

for i in test:
    test[i] = np.log(test[i])

ytest= np.array(test['EQ'])
ytest = pd.Series(ytest)
all_model_results = evaluate_trace(normal_trace, test, ytest)